{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load(dataset):\n",
    "    X = pd.read_csv('../data/%s' % dataset + '/%s_train.data' % dataset, header=None, sep=' ')\n",
    "    # For unknown for me reason, X is read with last column filled with NaN\n",
    "    X.drop(X.columns[[-1]], axis=1, inplace=True)\n",
    "    Y = pd.read_csv('../data/%s' % dataset + '/%s_train.solution' % dataset, header=None, sep=' ')[0]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectPercentile, VarianceThreshold\n",
    "from libscores import auc_cv\n",
    "from libscores import bac_cv\n",
    "\n",
    "def rf_model(x, y, p, e):\n",
    "    return Pipeline([   \n",
    "        ('variation_zero', VarianceThreshold(.1)),    \n",
    "        ('feature_selection', SelectPercentile(percentile=p, score_func=sklearn.feature_selection.f_classif)),\n",
    "        ('classification', RandomForestClassifier(n_estimators=e, random_state=1, n_jobs=-1, min_samples_split=1))\n",
    "    ]).fit(x, y), \"SELECT+RF percentile=%d\" % p + \" n_estimators=%d\" % e\n",
    "\n",
    "\n",
    "def et_model(x, y, p, e):\n",
    "    return Pipeline([\n",
    "        ('variation_zero', VarianceThreshold(.1)),\n",
    "        ('feature_selection', SelectPercentile(percentile=p, score_func=sklearn.feature_selection.f_classif)),\n",
    "        ('classification', ExtraTreesClassifier(n_estimators=e, n_jobs=-1, random_state=1, min_samples_split=1))\n",
    "    ]).fit(x, y), \"SELECT+ET percentile=%d\" % p + \" n_estimators=%d\" % e\n",
    "\n",
    "# def bagg_model(x, y, p, e):\n",
    "#     return Pipeline([\n",
    "#         ('variation_zero', VarianceThreshold(.1)),\n",
    "#         ('feature_selection', SelectPercentile(percentile=p, score_func=sklearn.feature_selection.f_classif)),\n",
    "#         ('classification', BaggingClassifier(base_estimator=None, n_estimators=e, max_samples=1.0, \n",
    "#                                              max_features=1.0, bootstrap=True, \n",
    "#                                              bootstrap_features=False, oob_score=False, n_jobs=-1, \n",
    "#                                              random_state=1, verbose=0)),\n",
    "#         ]).fit(x, y), \"SELECT+BAGGING percentile=%d\" % p + \" n_estimators=%d\" % e\n",
    "\n",
    "# def ada_model(x, y, p, e):\n",
    "#     return Pipeline([\n",
    "#         ('variation_zero', VarianceThreshold(.1)),\n",
    "#         ('feature_selection', SelectPercentile(percentile=p, score_func=sklearn.feature_selection.f_classif)),\n",
    "#         ('classification', AdaBoostClassifier(base_estimator=None, n_estimators=e, \n",
    "#                                               learning_rate=1.0, algorithm='SAMME.R', random_state=1))\n",
    "#     ]).fit(x, y), \"SELECT+ADA_BOOST percentile=%d\" % p + \" n_estimators=%d\" % e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process(X, Y, model_function, metrics_function, best_model, best_metrics, best_label):\n",
    "    p = -1\n",
    "    for e in [100, 200, 270]:\n",
    "        # Start optimization from previous point\n",
    "        if p > 0:\n",
    "            l, r = max(1, p - 25), min(90, p + 25)\n",
    "        elif len(X) < 200:\n",
    "            l = 50, 99\n",
    "        elif len(X) > 1000:\n",
    "            l, r = 1, 40\n",
    "        else: \n",
    "            l, r = 1, 90\n",
    "\n",
    "        # Left\n",
    "        model_l, label_l = model_function(X, Y, l, e)\n",
    "        metrics_l = metrics_function(model_l, X, Y)\n",
    "        if metrics_l > best_metrics:\n",
    "            best_metrics = metrics_l; best_label = label_l; best_model = model_l\n",
    "        print \"Processed: %s\" % label_l + \" score: %f\" % metrics_l\n",
    "\n",
    "        # Rigth\n",
    "        model_r, label_r = model_function(X, Y, r, e)\n",
    "        metrics_r = metrics_function(model_r, X, Y)\n",
    "        if metrics_r > best_metrics:\n",
    "            best_metrics = metrics_r; best_label = label_r; best_model = model_r\n",
    "        print \"Processed: %s\" % label_r + \" score: %f\" % metrics_r\n",
    "\n",
    "        no_progress = 0\n",
    "        while True:\n",
    "            # Median point\n",
    "            p = (l + r) / 2\n",
    "            model_p, label_p = model_function(X, Y, p, e)\n",
    "            metrics_p = metrics_function(model_p, X, Y)\n",
    "            if metrics_p > best_metrics:\n",
    "                best_metrics = metrics_p; best_label = label_p; best_model = model_p; no_progress = 0\n",
    "            else:\n",
    "                no_progress += 1\n",
    "            print \"Processed: %s\" % label_p + \" score: %f\" % metrics_p\n",
    "            \n",
    "            if metrics_l > metrics_r:\n",
    "                r, model_r, metrics_r, label_r = p, model_p, metrics_p, label_p\n",
    "            else:\n",
    "                l, model_l, metrics_l, label_l = p, model_p, metrics_p, label_p\n",
    "            if no_progress >= 2 or l == r:\n",
    "                break\n",
    "\n",
    "    return best_model, best_metrics, best_label\n",
    "\n",
    "def optimize(name, X, Y):\n",
    "    \"\"\"Performs optimization for given dataset\"\"\"\n",
    "    \n",
    "    if name in [\"christine\", \"jasmine\", \"madeline\", \"philippine\", \"sylvine\"]:\n",
    "        metrics_function = bac_cv\n",
    "    else:\n",
    "        metrics_function = auc_cv\n",
    "        \n",
    "    # Starting point\n",
    "    model, metrics, label = None, 0, None\n",
    "\n",
    "    model, metrics, label = process(X, Y, rf_model, metrics_function, model, metrics, label)\n",
    "    model, metrics, label = process(X, Y, et_model, metrics_function, model, metrics, label)\n",
    "#     model, metrics, label = process(X, Y, bagg_model, metrics_function, model, metrics, label)\n",
    "#     model, metrics, label = process(X, Y, ada_model, metrics_function, model, metrics, label)\n",
    "    \n",
    "    print \"%s \" % name + \" best model: %s\" % label + \" metrics: %f\" % metrics\n",
    "    return model, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSING christine\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for name in [\"christine\", \"jasmine\", \"madeline\", \"philippine\", \"sylvine\"]:\n",
    "    print \"PROCESSING %s\" % name\n",
    "    X, Y = load(name)\n",
    "    optimize(name, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
