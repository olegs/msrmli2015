{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load(dataset):\n",
    "    X = pd.read_csv('../data/%s' % dataset + '/%s_train.data' % dataset, header=None, sep=' ')\n",
    "    # For unknown for me reason, X is read with last column filled with NaN\n",
    "    X.drop(X.columns[[-1]], axis=1, inplace=True)\n",
    "    Y = pd.read_csv('../data/%s' % dataset + '/%s_train.solution' % dataset, header=None, sep=' ')[0]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectPercentile, VarianceThreshold\n",
    "from libscores import auc_cv\n",
    "from libscores import bac_cv\n",
    "\n",
    "def rf_model(x, y, p, e):\n",
    "    return Pipeline([           \n",
    "        ('feature_selection', SelectPercentile(percentile=p, score_func=sklearn.feature_selection.f_classif)),\n",
    "        ('classification', RandomForestClassifier(n_estimators=e, random_state=1, n_jobs=-1))\n",
    "    ]).fit(x, y), \"SELECT+RF percentile=%d\" % p + \" n_estimators=%d\" % e\n",
    "\n",
    "\n",
    "def et_model(x, y, p, e):\n",
    "    return Pipeline([           \n",
    "        ('feature_selection', SelectPercentile(percentile=p, score_func=sklearn.feature_selection.f_classif)),\n",
    "        ('classification', ExtraTreesClassifier(n_estimators=e, n_jobs=-1, random_state=1))\n",
    "    ]).fit(x, y), \"SELECT+ET percentile=%d\" % p + \" n_estimators=%d\" % e\n",
    "\n",
    "def bagg_model(x, y, p, e):\n",
    "    return Pipeline([           \n",
    "        ('feature_selection', SelectPercentile(percentile=p, score_func=sklearn.feature_selection.f_classif)),\n",
    "        ('classification', BaggingClassifier(base_estimator=None, n_estimators=e, max_samples=1.0, max_features=1.0, bootstrap=True, bootstrap_features=False, oob_score=False, n_jobs=-1, random_state=1, verbose=0))\n",
    "    ]).fit(x, y), \"SELECT+ET percentile=%d\" % p + \" n_estimators=%d\" % e\n",
    "\n",
    "\n",
    "def ada_model(x, y, p, e):\n",
    "    return Pipeline([           \n",
    "        ('feature_selection', SelectPercentile(percentile=p, score_func=sklearn.feature_selection.f_classif)),\n",
    "        ('classification', AdaBoostClassifier(base_estimator=None, n_estimators=e, learning_rate=1.0, algorithm='SAMME.R', n_jobs=-1, random_state=1))\n",
    "    ]).fit(x, y), \"SELECT+ET percentile=%d\" % p + \" n_estimators=%d\" % e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(X, Y, model_function, metrics_function, best_model, best_metrics, best_label):\n",
    "    p = -1\n",
    "    for e in [10, 50, 100, 200, 300]:\n",
    "        # Start optimization\n",
    "        if p > 0:\n",
    "            l = max(1, p - 20)\n",
    "            r = min(r, p + 20)\n",
    "        else:\n",
    "            l = 1\n",
    "            r = 50\n",
    "        # Step left\n",
    "        model_l, label_l = model_function(X, Y, l, e)\n",
    "        metrics_l = metrics_function(model_l, X, Y)\n",
    "        if metrics_l > best_metrics:\n",
    "            best_metrics = metrics_l; best_label = label_l; best_model = model_l\n",
    "        print \"Processed: %s\" % label_l + \" score: %f\" % metrics_l\n",
    "\n",
    "        # Step rigth\n",
    "        model_r, label_r = model_function(X, Y, r, e)\n",
    "        metrics_r = metrics_function(model_r, X, Y)\n",
    "        if metrics_r > best_metrics:\n",
    "            best_metrics = metrics_r; best_label = label_r; best_model = model_r\n",
    "        print \"Processed: %s\" % label_r + \" score: %f\" % metrics_r\n",
    "\n",
    "        step = 0\n",
    "        while step < 10:\n",
    "            improved = False\n",
    "            step += 1\n",
    "            p = (l + r) / 2\n",
    "            model_p, label_p = model_function(X, Y, p, e)\n",
    "            metrics_p = metrics_function(model_p, X, Y)\n",
    "            if metrics_p > best_metrics:\n",
    "                best_metrics = metrics_p; best_label = label_p; best_model = model_p; improved = True\n",
    "            print \"Processed: %s\" % label_p + \" score: %f\" % metrics_p\n",
    "            \n",
    "            if metrics_l > metrics_r:\n",
    "                r, model_r, metrics_r, label_r = p, model_p, metrics_p, label_p\n",
    "            else:\n",
    "                l, model_l, metrics_l, label_l = p, model_p, metrics_p, label_p\n",
    "            if not improved and step >= 5 or l == r:\n",
    "                break\n",
    "\n",
    "    return best_model, best_metrics, best_label\n",
    "\n",
    "def optimize(X, Y):\n",
    "    \"\"\"Performs optimization for given dataset\"\"\"\n",
    "    \n",
    "    if name in [\"christine\", \"jasmine\", \"madeline\", \"philippine\", \"sylvine\"]:\n",
    "        metrics_function = bac_cv\n",
    "    else:\n",
    "        metrics_function = auc_cv\n",
    "        \n",
    "    model = None\n",
    "    metrics = 0\n",
    "    label = None    \n",
    "\n",
    "    # Lets remove constant features\n",
    "    X = VarianceThreshold(.1).fit_transform(X)\n",
    "\n",
    "    model, metrics, label = process(X, Y, rf_model, metrics_function, model, metrics, label)\n",
    "    model, metrics, label = process(X, Y, et_model, metrics_function, model, metrics, label)\n",
    "    model, metrics, label = process(X, Y, bagg_model, metrics_function, model, metrics, label)\n",
    "    model, metrics, label = process(X, Y, ada_model, metrics_function, model, metrics, label)\n",
    "\n",
    "    print \"Best model: %s\" % label + \" metrics: %f\" % metrics\n",
    "    return model, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print \"Hello\"\n",
    "for name in [\"jasmine\", \"madeline\", \"philippine\", \"sylvine\"]:\n",
    "    print \"PROCESSING %s\" % name\n",
    "    X, Y = load(name)\n",
    "    optimize(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}