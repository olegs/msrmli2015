{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load(dataset):\n",
    "    X = pd.read_csv('../data/%s' % dataset + '/%s_train.data' % dataset, header=None, sep=' ')\n",
    "    X.head(5)\n",
    "    # For unknown for me reason, X is read with last column filled with NaN\n",
    "    X.drop(X.columns[[-1]], axis=1, inplace=True)\n",
    "    Y = pd.read_csv('../data/%s' % dataset + '/%s_train.solution' % dataset, header=None, sep=' ')[0]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import sqrt, exp\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectPercentile, VarianceThreshold\n",
    "from libscores import auc_cv\n",
    "from libscores import bac_cv\n",
    "\n",
    "def rf_model(x, y, p, e):\n",
    "    return Pipeline([   \n",
    "        ('variation_zero', VarianceThreshold(.1)),    \n",
    "        ('feature_selection', SelectPercentile(percentile=p, score_func=sklearn.feature_selection.f_classif)),\n",
    "        ('classification', RandomForestClassifier(n_estimators=e, random_state=1, n_jobs=-1, min_samples_split=1))\n",
    "    ]).fit(x, y), \"SELECT+RF percentile=%d\" % p + \" n_estimators=%d\" % e\n",
    "\n",
    "def rf_no_var_model(x, y, p, e):\n",
    "    return Pipeline([\n",
    "        ('variation_zero', VarianceThreshold(exp(-10))),\n",
    "        ('feature_selection', SelectPercentile(percentile=p, score_func=sklearn.feature_selection.f_classif)),\n",
    "        ('classification', RandomForestClassifier(n_estimators=e, random_state=1, n_jobs=-1, min_samples_split=1))\n",
    "    ]).fit(x, y), \"SELECT+RF_NO_VAR percentile=%d\" % p + \" n_estimators=%d\" % e\n",
    "\n",
    "def et_model(x, y, p, e):\n",
    "    return Pipeline([\n",
    "        ('variation_zero', VarianceThreshold(.1)),\n",
    "        ('feature_selection', SelectPercentile(percentile=p, score_func=sklearn.feature_selection.f_classif)),\n",
    "        ('classification', ExtraTreesClassifier(n_estimators=e, n_jobs=-1, random_state=1, min_samples_split=1))\n",
    "    ]).fit(x, y), \"SELECT+ET percentile=%d\" % p + \" n_estimators=%d\" % e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def process(X, Y, model_function, metrics_function, best_model, best_metrics, best_label, best_p, start):\n",
    "    for e in [100, 200, 270]:\n",
    "        # Start optimization from previous point\n",
    "        if best_p > 0:\n",
    "            l, r = max(1, best_p - 13), min(99, best_p + 13)\n",
    "        else:\n",
    "            l, r = 1, 99\n",
    "\n",
    "        # Left\n",
    "        model_l, label_l = model_function(X, Y, l, e)\n",
    "        metrics_l = metrics_function(model_l, X, Y)\n",
    "        if metrics_l > best_metrics:\n",
    "            best_metrics = metrics_l; best_label = label_l; best_model = model_l\n",
    "        print \"Processed: %s\" % label_l + \" score: %f\" % metrics_l\n",
    "\n",
    "        # Rigth\n",
    "        model_r, label_r = model_function(X, Y, r, e)\n",
    "        metrics_r = metrics_function(model_r, X, Y)\n",
    "        if metrics_r > best_metrics:\n",
    "            best_metrics = metrics_r; best_label = label_r; best_model = model_r\n",
    "        print \"Processed: %s\" % label_r + \" score: %f\" % metrics_r\n",
    "\n",
    "        no_progress = 0\n",
    "        while True:\n",
    "            # Check time!\n",
    "            if time.time() - start > 2 * 2 * 60 - 10:\n",
    "                return best_model, best_metrics, best_label, best_p\n",
    "            # Median point\n",
    "            p = (l + r) / 2\n",
    "            model_p, label_p = model_function(X, Y, p, e)\n",
    "            metrics_p = metrics_function(model_p, X, Y)\n",
    "            if metrics_p > best_metrics:\n",
    "                best_metrics = metrics_p; best_label = label_p; best_model = model_p; best_p = p; no_progress = 0\n",
    "            else:\n",
    "                no_progress += 1\n",
    "            print \"Processed: %s\" % label_p + \" score: %f\" % metrics_p + \". No progress %d steps\" % no_progress\n",
    "            \n",
    "            if metrics_l > metrics_r:\n",
    "                r, model_r, metrics_r, label_r = p, model_p, metrics_p, label_p\n",
    "            else:\n",
    "                l, model_l, metrics_l, label_l = p, model_p, metrics_p, label_p\n",
    "            if no_progress >= 3 or l == r:\n",
    "                break\n",
    "\n",
    "    return best_model, best_metrics, best_label, best_p\n",
    "\n",
    "def optimize(name, X, Y):\n",
    "    \"\"\"Performs optimization for given dataset\"\"\"\n",
    "    start = time.time()\n",
    "    \n",
    "    if name in [\"christine\", \"jasmine\", \"madeline\", \"philippine\", \"sylvine\"]:\n",
    "        metrics_function = bac_cv\n",
    "    else:\n",
    "        metrics_function = auc_cv\n",
    "        \n",
    "    # Starting point\n",
    "    model, metrics, label, p = None, 0, None, -1\n",
    "    \n",
    "    if X.shape[0] / X.shape[1] > 10 or X.shape[1] > 1000:\n",
    "        model, metrics, label, p = process(X, Y, rf_no_var_model, metrics_function, model, metrics, label, p, start) \n",
    "    else:\n",
    "        model, metrics, label, p = process(X, Y, et_model, metrics_function, model, metrics, label, p, start)\n",
    "    model, metrics, label, p = process(X, Y, rf_model, metrics_function, model, metrics, label, p, start)\n",
    "\n",
    "    \n",
    "    print \"%s \" % name + \" best model: %s\" % label + \" metrics: %f\" % metrics\n",
    "    print \"Time %dsec\" % (time.time() - start)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSING christine\n",
      "Size: 5418x1636\n",
      "Processed: SELECT+RF_NO_VAR percentile=1 n_estimators=100 score: 0.414544\n",
      "Processed: SELECT+RF_NO_VAR percentile=99 n_estimators=100 score: 0.439646\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for name in [\"christine\", \"jasmine\", \"madeline\", \"philippine\", \"sylvine\"]:\n",
    "    print \"PROCESSING %s\" % name\n",
    "    X, Y = load(name)\n",
    "    print \"Size: %d\" % X.shape[0] + \"x%d\" % X.shape[1]\n",
    "    optimize(name, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
